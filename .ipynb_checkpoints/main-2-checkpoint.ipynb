{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd1e7eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import dataset,get_Kfold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from models import MLP\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import random\n",
    "from TrainandTest import train_MLP,test_MLP\n",
    "\n",
    "def same_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "same_seeds(114514)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5366db30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models(model):\n",
    "    if model=='MLP':\n",
    "        return MLP(5,64)\n",
    "\n",
    "def train_epoch(train_loader,model,criterion,optimizer,device):\n",
    "    losses = []\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        labels = labels.to(device)\n",
    "        inputs = inputs.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels.unsqueeze(1))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    losses.append(loss.item())\n",
    "    return sum(losses)/len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9ec5647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------[ K:1 Type:odd N_size:<126 ]-----------\n",
      "loss:4.661383152008057 saving...\n",
      "loss:1.1260937452316284 saving...\n",
      "loss:0.735753059387207 saving...\n",
      "loss:0.2675648629665375 saving...\n",
      "loss:0.22926099598407745 saving...\n",
      "loss:0.13120757043361664 saving...\n",
      "loss:0.06719787418842316 saving...\n",
      "loss:0.02797296643257141 saving...\n",
      "loss:0.013046622276306152 saving...\n",
      "loss:0.011129896156489849 saving...\n",
      "loss:0.008729195222258568 saving...\n",
      "loss:0.008662995882332325 saving...\n",
      "loss:0.0043966928496956825 saving...\n",
      "loss:0.003387824399396777 saving...\n",
      "loss:0.0027445522136986256 saving...\n",
      "loss:0.002673025708645582 saving...\n",
      "loss:0.0025482079945504665 saving...\n",
      "loss:0.0012215834576636553 saving...\n",
      "loss:0.0004428921383805573 saving...\n",
      "loss:0.0003331950574647635 saving...\n",
      "loss:0.00019681926642078906 saving...\n",
      "loss:9.933613910106942e-05 saving...\n",
      "loss:9.410178608959541e-05 saving...\n",
      "loss:3.598770490498282e-05 saving...\n",
      "loss:2.8738262699334882e-05 saving...\n",
      "Test Loss: 0.0089164060, Test RMSE: 0.0944267227\n",
      "-----------[ K:2 Type:odd N_size:<126 ]-----------\n",
      "loss:7.954925060272217 saving...\n",
      "loss:1.632442593574524 saving...\n",
      "loss:0.9399387240409851 saving...\n",
      "loss:0.8975734710693359 saving...\n",
      "loss:0.5226899981498718 saving...\n",
      "loss:0.4054621160030365 saving...\n",
      "loss:0.24175813794136047 saving...\n",
      "loss:0.09673280268907547 saving...\n",
      "loss:0.08492779731750488 saving...\n",
      "loss:0.05849234014749527 saving...\n",
      "loss:0.045439720153808594 saving...\n",
      "loss:0.04456538334488869 saving...\n",
      "loss:0.019766410812735558 saving...\n",
      "loss:0.011167233809828758 saving...\n",
      "loss:0.00540656503289938 saving...\n",
      "loss:0.005223206244409084 saving...\n",
      "loss:0.00469968793913722 saving...\n",
      "loss:0.001296181813813746 saving...\n",
      "loss:0.000995427486486733 saving...\n",
      "loss:0.000700955162756145 saving...\n",
      "loss:0.000672056048642844 saving...\n",
      "loss:0.0006013653473928571 saving...\n",
      "loss:0.00046490805107168853 saving...\n",
      "loss:0.0004222186398692429 saving...\n",
      "loss:0.00038501876406371593 saving...\n",
      "loss:0.0003399837005417794 saving...\n",
      "loss:0.00033900627749972045 saving...\n",
      "loss:0.0003363465366419405 saving...\n",
      "loss:0.0003119108732789755 saving...\n",
      "loss:0.0002741003700066358 saving...\n",
      "Test Loss: 0.0437592901, Test RMSE: 0.2091872131\n"
     ]
    }
   ],
   "source": [
    "with open('config.json','r',encoding='utf-8')as f:\n",
    "    config_list = json.load(f)\n",
    "#device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'cpu'\n",
    "file = './data/jiji small126.xlsx'\n",
    "batch_size = 300\n",
    "\n",
    "for config in config_list:\n",
    "    Type = config['Type']\n",
    "    N_size = config['N_size']\n",
    "    num_epoch = config['num_epoch']\n",
    "    lr = config['lr']\n",
    "    k = config['k']\n",
    "    alpha,beta = config['alpha'],config['beta']\n",
    "    \n",
    "    K_fold_data = get_Kfold(file,2)\n",
    "    for k_step,(trian_data,test_data) in enumerate(K_fold_data):\n",
    "        print(f\"-----------[ K:{k_step+1} Type:{Type} N_size:{N_size} ]-----------\")\n",
    "        model = get_models(config['model']).to(device)\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(),lr=lr)\n",
    "        lr_scheduler = optim.lr_scheduler.LambdaLR(optimizer,lambda x: 1 - x/num_epoch,last_epoch=-1)\n",
    "        \n",
    "        scaler = MinMaxScaler()\n",
    "        trian_data = dataset(trian_data,Type,N_size)\n",
    "        test_data = dataset(test_data,Type,N_size)\n",
    "        \n",
    "        train_loader = DataLoader(dataset=trian_data,batch_size=batch_size)\n",
    "        test_loader = DataLoader(dataset=test_data,batch_size=batch_size)\n",
    "        \n",
    "        \n",
    "        train_MLP(train_loader,model,criterion,optimizer,num_epoch,k_step,lr_scheduler)\n",
    "        test_MLP(test_loader,model,k_step,criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153dfa1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
