{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd1e7eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import dataset,data_deal\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from models import *\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from sklearn.model_selection import KFold\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import random\n",
    "from TrainandTest import train_MLP,test_MLP\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def same_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7abae5",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59e2b25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "file = './data/total 12 data.xlsx'\n",
    "data = pd.read_excel(file,engine=\"openpyxl\")\n",
    "data = np.array(data)\n",
    "l = len(data)\n",
    "para_path = './save/parameter'\n",
    "batch_size = 300\n",
    "plot = True\n",
    "# np.set_printoptions(threshold=np.sys.maxsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bc2a21",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8231b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complexity(model):\n",
    "    param_squared_sums = {}\n",
    "    encoder_parameters = list(filter(lambda x: x[0].startswith('encoder'),list(model.named_parameters())))\n",
    "    for name, param in encoder_parameters:\n",
    "#         print(param)\n",
    "        if 'weight' in name:\n",
    "            param_squared_sums[name] = torch.sum(param ** 2)\n",
    "    return sum(param_squared_sums.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99a53e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss = 0\n",
    "flag =  3\n",
    "Type = 'odd-even'\n",
    "N_size = '<=126'\n",
    "lr = 0.1\n",
    "k = 10\n",
    "alpha = 0.5\n",
    "input_size = 12\n",
    "epsilon = 0\n",
    "seed1,seed2 = 0,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e24643d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=k ,shuffle=True,random_state=seed1)\n",
    "\n",
    "total_data = dataset(data,Type,N_size,input_size)\n",
    "total_data = np.array(total_data,dtype = object)\n",
    "\n",
    "X = total_data[:,0]\n",
    "y = total_data[:,1].astype(np.float32)\n",
    "\n",
    "temp_loss = 0\n",
    "l1= X[0].shape[0]\n",
    "l2 =len(X)\n",
    "results_df = pd.DataFrame()\n",
    "total_loss1 = 0\n",
    "total_loss2 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f02555dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ae init weight 26.316516876220703\n",
      "mlp init weight 25.76162338256836\n",
      "ae test loss:0.23668548464775085\n",
      "mlp test loss:0.1414794772863388\n",
      "ae trained weight 15.437347412109375\n",
      "mlp trained weight 106.82365417480469\n",
      "\n",
      "ae init weight 27.000120162963867\n",
      "mlp init weight 25.392383575439453\n",
      "ae test loss:0.17538093030452728\n",
      "mlp test loss:0.11883269995450974\n",
      "ae trained weight 40.47714614868164\n",
      "mlp trained weight 107.11579895019531\n",
      "\n",
      "ae init weight 27.000120162963867\n",
      "mlp init weight 25.392383575439453\n",
      "ae test loss:0.10835425555706024\n",
      "mlp test loss:0.13103953003883362\n",
      "ae trained weight 53.417240142822266\n",
      "mlp trained weight 135.44088745117188\n",
      "\n",
      "ae init weight 27.000120162963867\n",
      "mlp init weight 25.392383575439453\n",
      "ae test loss:0.10604821890592575\n",
      "mlp test loss:0.08621431142091751\n",
      "ae trained weight 39.9582405090332\n",
      "mlp trained weight 119.6258544921875\n",
      "\n",
      "ae init weight 27.000120162963867\n",
      "mlp init weight 25.392383575439453\n",
      "ae test loss:0.11232786625623703\n",
      "mlp test loss:0.17712973058223724\n",
      "ae trained weight 51.400760650634766\n",
      "mlp trained weight 112.03639221191406\n",
      "\n",
      "ae init weight 27.000120162963867\n",
      "mlp init weight 25.392383575439453\n",
      "ae test loss:0.14661942422389984\n",
      "mlp test loss:0.5079604387283325\n",
      "ae trained weight 25.61258316040039\n",
      "mlp trained weight 117.92456817626953\n",
      "\n",
      "ae init weight 27.000120162963867\n",
      "mlp init weight 25.392383575439453\n",
      "ae test loss:0.09671638160943985\n",
      "mlp test loss:0.1039092019200325\n",
      "ae trained weight 53.478675842285156\n",
      "mlp trained weight 120.44171142578125\n",
      "\n",
      "ae init weight 27.000120162963867\n",
      "mlp init weight 25.392383575439453\n",
      "ae test loss:0.08666599541902542\n",
      "mlp test loss:0.11784186214208603\n",
      "ae trained weight 48.02656555175781\n",
      "mlp trained weight 112.06729125976562\n",
      "\n",
      "ae init weight 27.000120162963867\n",
      "mlp init weight 25.392383575439453\n",
      "ae test loss:0.055417824536561966\n",
      "mlp test loss:0.0787224993109703\n",
      "ae trained weight 57.20682907104492\n",
      "mlp trained weight 121.28919982910156\n",
      "\n",
      "ae init weight 27.000120162963867\n",
      "mlp init weight 25.392383575439453\n",
      "ae test loss:0.1445813924074173\n",
      "mlp test loss:0.1537076234817505\n",
      "ae trained weight 63.82453155517578\n",
      "mlp trained weight 117.21275329589844\n",
      "\n",
      "tensor(0.3574) tensor(0.4006)\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "#     same_seeds(seed2)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    l3 = len(y_test)\n",
    "    ae_model = get_models(\"AE_MLP\",input_size,epsilon)\n",
    "    mlp_model = get_models(\"MLP\",input_size,epsilon)\n",
    "    print(f\"ae init weight {complexity(ae_model)}\")\n",
    "    print(f\"mlp init weight {complexity(mlp_model)}\")\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train,X_test,y_train,y_test,scaler = data_deal(X_train,X_test,y_train,y_test,scaler,input_size,flag)\n",
    "    same_seeds(seed2)\n",
    "    train_MLP(X_train,y_train,ae_model,lr,alpha,fold,para_path,flag)\n",
    "    same_seeds(seed2)\n",
    "    loss,_ = test_MLP(X_test,y_test,ae_model,fold,para_path,scaler,results_df,l1,flag)\n",
    "    total_loss1 = total_loss1 +loss\n",
    "    loss = loss / l3\n",
    "    print(f\"ae test loss:{loss.item()}\")\n",
    "    same_seeds(seed2)\n",
    "    train_MLP(X_train,y_train,mlp_model,lr,alpha,fold,para_path,flag)\n",
    "    same_seeds(seed2)\n",
    "    loss,results_df = test_MLP(X_test,y_test,mlp_model,fold,para_path,scaler,results_df,l1,flag)\n",
    "    total_loss2 = total_loss2 +loss\n",
    "    loss = loss / l3\n",
    "    print(f\"mlp test loss:{loss.item()}\")\n",
    "    print(f\"ae trained weight {complexity(ae_model)}\")\n",
    "    print(f\"mlp trained weight {complexity(mlp_model)}\\n\")\n",
    "    \n",
    "results_df.to_excel(f'test_data_and_outputs_{flag + 1}.xlsx', index=False)\n",
    "print((sum(total_loss1)/l2)**0.5,(sum(total_loss2)/l2)**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbccd29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
