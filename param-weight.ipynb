{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd1e7eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import dataset,data_deal\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from models import *\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from sklearn.model_selection import KFold\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import random\n",
    "from TrainandTest import train_MLP,test_MLP\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def same_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7abae5",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59e2b25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "file = './data/total 12 data.xlsx'\n",
    "data = pd.read_excel(file,engine=\"openpyxl\")\n",
    "data = np.array(data)\n",
    "l = len(data)\n",
    "para_path = './save/parameter'\n",
    "batch_size = 300\n",
    "plot = True\n",
    "# np.set_printoptions(threshold=np.sys.maxsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bc2a21",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8231b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complexity(model):\n",
    "    param_squared_sums = {}\n",
    "    encoder_parameters = list(filter(lambda x: x[0].startswith('encoder'),list(model.named_parameters())))\n",
    "    for name, param in encoder_parameters:\n",
    "#         print(param)\n",
    "        if 'weight' in name:\n",
    "            param_squared_sums[name] = torch.sum(param ** 2)\n",
    "    return sum(param_squared_sums.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99a53e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss = 0\n",
    "flag =  3\n",
    "Type = 'odd-even'\n",
    "N_size = '<=126'\n",
    "lr = 0.1\n",
    "k = 10\n",
    "alpha = 0.5\n",
    "input_size = 12\n",
    "epsilon = 0\n",
    "seed1,seed2 = 0,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e24643d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=k ,shuffle=True,random_state=seed1)\n",
    "\n",
    "total_data = dataset(data,Type,N_size,input_size)\n",
    "total_data = np.array(total_data,dtype = object)\n",
    "\n",
    "X = total_data[:,0]\n",
    "y = total_data[:,1].astype(np.float32)\n",
    "\n",
    "temp_loss = 0\n",
    "l1= X[0].shape[0]\n",
    "l2 =len(X)\n",
    "results_df = pd.DataFrame()\n",
    "total_loss1 = 0\n",
    "total_loss2 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f02555dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ae init weight 26.09284782409668\n",
      "mlp init weight 26.050159454345703\n",
      "ae test loss:0.045533765107393265\n",
      "mlp test loss:0.035664938390254974\n",
      "ae trained weight 55.252437591552734\n",
      "mlp trained weight 130.19735717773438\n",
      "\n",
      "ae init weight 27.000120162963867\n",
      "mlp init weight 25.392383575439453\n",
      "ae test loss:0.03448549285531044\n",
      "mlp test loss:0.023873208090662956\n",
      "ae trained weight 55.061004638671875\n",
      "mlp trained weight 145.17710876464844\n",
      "\n",
      "ae init weight 27.000120162963867\n",
      "mlp init weight 25.392383575439453\n",
      "ae test loss:0.028917694464325905\n",
      "mlp test loss:0.026189304888248444\n",
      "ae trained weight 78.40351104736328\n",
      "mlp trained weight 140.8511505126953\n",
      "\n",
      "ae init weight 27.000120162963867\n",
      "mlp init weight 25.392383575439453\n",
      "ae test loss:0.10799577832221985\n",
      "mlp test loss:0.12747976183891296\n",
      "ae trained weight 43.286380767822266\n",
      "mlp trained weight 145.49392700195312\n",
      "\n",
      "ae init weight 27.000120162963867\n",
      "mlp init weight 25.392383575439453\n",
      "ae test loss:0.040041733533144\n",
      "mlp test loss:0.032169077545404434\n",
      "ae trained weight 52.3355827331543\n",
      "mlp trained weight 142.55795288085938\n",
      "\n",
      "ae init weight 27.000120162963867\n",
      "mlp init weight 25.392383575439453\n",
      "ae test loss:0.046773768961429596\n",
      "mlp test loss:0.03092944622039795\n",
      "ae trained weight 47.48183822631836\n",
      "mlp trained weight 145.91510009765625\n",
      "\n",
      "ae init weight 27.000120162963867\n",
      "mlp init weight 25.392383575439453\n",
      "ae test loss:0.03820587694644928\n",
      "mlp test loss:0.04538745805621147\n",
      "ae trained weight 62.5882568359375\n",
      "mlp trained weight 142.92347717285156\n",
      "\n",
      "ae init weight 27.000120162963867\n",
      "mlp init weight 25.392383575439453\n",
      "ae test loss:0.0637635886669159\n",
      "mlp test loss:0.07116121798753738\n",
      "ae trained weight 50.30552673339844\n",
      "mlp trained weight 142.22705078125\n",
      "\n",
      "ae init weight 27.000120162963867\n",
      "mlp init weight 25.392383575439453\n",
      "ae test loss:0.057141512632369995\n",
      "mlp test loss:0.04304780811071396\n",
      "ae trained weight 136.50823974609375\n",
      "mlp trained weight 157.234130859375\n",
      "\n",
      "ae init weight 27.000120162963867\n",
      "mlp init weight 25.392383575439453\n",
      "ae test loss:0.06624941527843475\n",
      "mlp test loss:0.046779900789260864\n",
      "ae trained weight 46.975074768066406\n",
      "mlp trained weight 158.78843688964844\n",
      "\n",
      "tensor(0.2300) tensor(0.2197)\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "#     same_seeds(seed2)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    l3 = len(y_test)\n",
    "    ae_model = get_models(\"AE_MLP\",input_size,epsilon)\n",
    "    mlp_model = get_models(\"MLP\",input_size,epsilon)\n",
    "    print(f\"ae init weight {complexity(ae_model)}\")\n",
    "    print(f\"mlp init weight {complexity(mlp_model)}\")\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train,X_test,y_train,y_test,scaler = data_deal(X_train,X_test,y_train,y_test,scaler,input_size,flag)\n",
    "    same_seeds(seed2)\n",
    "    train_MLP(X_train,y_train,ae_model,lr,alpha,fold,para_path,flag)\n",
    "    same_seeds(seed2)\n",
    "    loss,_ = test_MLP(X_test,y_test,ae_model,fold,para_path,scaler,results_df,l1,flag)\n",
    "    total_loss1 = total_loss1 +loss\n",
    "    loss = loss / l3\n",
    "    print(f\"ae test loss:{loss.item()}\")\n",
    "    same_seeds(seed2)\n",
    "    train_MLP(X_train,y_train,mlp_model,lr,alpha,fold,para_path,flag)\n",
    "    same_seeds(seed2)\n",
    "    loss,results_df = test_MLP(X_test,y_test,mlp_model,fold,para_path,scaler,results_df,l1,flag)\n",
    "    total_loss2 = total_loss2 +loss\n",
    "    loss = loss / l3\n",
    "    print(f\"mlp test loss:{loss.item()}\")\n",
    "    print(f\"ae trained weight {complexity(ae_model)}\")\n",
    "    print(f\"mlp trained weight {complexity(mlp_model)}\\n\")\n",
    "    \n",
    "results_df.to_excel(f'test_data_and_outputs_{flag + 1}.xlsx', index=False)\n",
    "print((sum(total_loss1)/l2)**0.5,(sum(total_loss2)/l2)**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbccd29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
