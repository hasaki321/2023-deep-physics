{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd1e7eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import dataset,data_deal\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from models import *\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from sklearn.model_selection import KFold\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import random\n",
    "from TrainandTest import train_MLP,test_MLP\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def same_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7abae5",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59e2b25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "file = './data/total 12 data.xlsx'\n",
    "data = pd.read_excel(file,engine=\"openpyxl\")\n",
    "data = np.array(data)\n",
    "l = len(data)\n",
    "para_path = './save/parameter'\n",
    "batch_size = 300\n",
    "plot = True\n",
    "# np.set_printoptions(threshold=np.sys.maxsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bc2a21",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8231b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complexity(model):\n",
    "    param_squared_sums = {}\n",
    "    encoder_parameters = list(filter(lambda x: x[0].startswith('encoder'),list(model.named_parameters())))\n",
    "    for name, param in encoder_parameters:\n",
    "#         print(param)\n",
    "        if 'weight' in name:\n",
    "            param_squared_sums[name] = torch.sum(param ** 2)\n",
    "    return sum(param_squared_sums.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "99a53e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss = 0\n",
    "flag =  3\n",
    "Type = 'odd-even'\n",
    "N_size = '>126'\n",
    "lr = 0.1\n",
    "k = 10\n",
    "alpha = 0.5\n",
    "input_size = 12\n",
    "epsilon = 0\n",
    "seed1,seed2 = 863522885,3678903281"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e24643d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=k ,shuffle=True,random_state=seed1)\n",
    "\n",
    "total_data = dataset(data,Type,N_size,input_size)\n",
    "total_data = np.array(total_data,dtype = object)\n",
    "\n",
    "X = total_data[:,0]\n",
    "y = total_data[:,1].astype(np.float32)\n",
    "\n",
    "temp_loss = 0\n",
    "l1= X[0].shape[0]\n",
    "l2 =len(X)\n",
    "results_df = pd.DataFrame()\n",
    "total_loss1 = 0\n",
    "total_loss2 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f02555dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ae init weight 27.345661163330078\n",
      "mlp init weight 26.728137969970703\n",
      "ae test loss:0.1722031533718109\n",
      "mlp test loss:0.17812763154506683\n",
      "ae trained weight 266.90399169921875\n",
      "mlp trained weight 257.028564453125\n",
      "\n",
      "ae init weight 27.345661163330078\n",
      "mlp init weight 26.728137969970703\n",
      "ae test loss:0.016390720382332802\n",
      "mlp test loss:0.08908800035715103\n",
      "ae trained weight 268.48944091796875\n",
      "mlp trained weight 268.5432434082031\n",
      "\n",
      "ae init weight 27.345661163330078\n",
      "mlp init weight 26.728137969970703\n",
      "ae test loss:0.15183217823505402\n",
      "mlp test loss:0.21014763414859772\n",
      "ae trained weight 253.21688842773438\n",
      "mlp trained weight 273.4781494140625\n",
      "\n",
      "ae init weight 27.345661163330078\n",
      "mlp init weight 26.728137969970703\n",
      "ae test loss:0.0837012454867363\n",
      "mlp test loss:0.19017934799194336\n",
      "ae trained weight 260.70892333984375\n",
      "mlp trained weight 276.520263671875\n",
      "\n",
      "ae init weight 27.345661163330078\n",
      "mlp init weight 26.728137969970703\n",
      "ae test loss:0.09642874449491501\n",
      "mlp test loss:0.23667007684707642\n",
      "ae trained weight 257.493896484375\n",
      "mlp trained weight 260.6327819824219\n",
      "\n",
      "ae init weight 27.345661163330078\n",
      "mlp init weight 26.728137969970703\n",
      "ae test loss:0.07025208324193954\n",
      "mlp test loss:0.13905301690101624\n",
      "ae trained weight 270.37713623046875\n",
      "mlp trained weight 261.76458740234375\n",
      "\n",
      "ae init weight 27.345661163330078\n",
      "mlp init weight 26.728137969970703\n",
      "ae test loss:0.12562716007232666\n",
      "mlp test loss:0.21478517353534698\n",
      "ae trained weight 276.83917236328125\n",
      "mlp trained weight 261.0849609375\n",
      "\n",
      "ae init weight 27.345661163330078\n",
      "mlp init weight 26.728137969970703\n",
      "ae test loss:0.06495658308267593\n",
      "mlp test loss:0.07916201651096344\n",
      "ae trained weight 263.1451416015625\n",
      "mlp trained weight 270.6095886230469\n",
      "\n",
      "ae init weight 27.345661163330078\n",
      "mlp init weight 26.728137969970703\n",
      "ae test loss:0.06967047601938248\n",
      "mlp test loss:0.07301516085863113\n",
      "ae trained weight 268.3360900878906\n",
      "mlp trained weight 258.9895935058594\n",
      "\n",
      "ae init weight 27.345661163330078\n",
      "mlp init weight 26.728137969970703\n",
      "ae test loss:0.04044758155941963\n",
      "mlp test loss:0.12560981512069702\n",
      "ae trained weight 264.5938415527344\n",
      "mlp trained weight 272.69598388671875\n",
      "\n",
      "tensor(0.2996) tensor(0.3933)\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    same_seeds(seed2)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    l3 = len(y_test)\n",
    "    ae_model = get_models(\"AE_MLP\",input_size,epsilon)\n",
    "    mlp_model = get_models(\"MLP\",input_size,epsilon)\n",
    "    print(f\"ae init weight {complexity(ae_model)}\")\n",
    "    print(f\"mlp init weight {complexity(mlp_model)}\")\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train,X_test,y_train,y_test,scaler = data_deal(X_train,X_test,y_train,y_test,scaler,input_size,flag)\n",
    "    same_seeds(seed2)\n",
    "    train_MLP(X_train,y_train,ae_model,lr,alpha,fold,para_path,flag)\n",
    "    same_seeds(seed2)\n",
    "    loss,_ = test_MLP(X_test,y_test,ae_model,fold,para_path,scaler,results_df,l1,flag)\n",
    "    total_loss1 = total_loss1 +loss\n",
    "    loss = loss / l3\n",
    "    print(f\"ae test loss:{loss.item()}\")\n",
    "    same_seeds(seed2)\n",
    "    train_MLP(X_train,y_train,mlp_model,lr,alpha,fold,para_path,flag)\n",
    "    same_seeds(seed2)\n",
    "    loss,results_df = test_MLP(X_test,y_test,mlp_model,fold,para_path,scaler,results_df,l1,flag)\n",
    "    total_loss2 = total_loss2 +loss\n",
    "    loss = loss / l3\n",
    "    print(f\"mlp test loss:{loss.item()}\")\n",
    "    print(f\"ae trained weight {complexity(ae_model)}\")\n",
    "    print(f\"mlp trained weight {complexity(mlp_model)}\\n\")\n",
    "    \n",
    "results_df.to_excel(f'test_data_and_outputs_{flag + 1}.xlsx', index=False)\n",
    "print((sum(total_loss1)/l2)**0.5,(sum(total_loss2)/l2)**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbccd29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
